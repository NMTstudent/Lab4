# АНАЛИЗ ДАННЫХ И ИСКУССТВЕННЫЙ ИНТЕЛЛЕКТ [in GameDev]
Отчет по лабораторной работе #4 выполнил:
- Батраков Дмитрий Антонович
- НМТ212701
Отметка о выполнении заданий (заполняется студентом):

| Задание | Выполнение | Баллы |
| ------ | ------ | ------ |
| Задание 1 | * | 60 |
| Задание 2 | * | 20 |
| Задание 3 | # | 20 |

знак "*" - задание выполнено; знак "#" - задание не выполнено;

Работу проверили:
- к.т.н., доцент Денисов Д.В.
- к.э.н., доцент Панов М.А.
- ст. преп., Фадеев В.О.

[![N|Solid](https://cldup.com/dTxpPi9lDf.thumb.png)](https://nodesource.com/products/nsolid)

[![Build Status](https://travis-ci.org/joemccann/dillinger.svg?branch=master)](https://travis-ci.org/joemccann/dillinger)

Структура отчета

- Данные о работе: название работы, фио, группа, выполненные задания.
- Цель работы.
- Задание 1.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Задание 2.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Задание 3.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Выводы.
- ✨Magic ✨

## Цель работы

## Задание 1
### в проекте Unity реализовать перцептрон, который умеет производить вычисления:
- OR | дать комментарии о корретности работы
- AND | дать комментарии о корретности работы
- NAND | дать комментарии о корретности работы
- XOR | дать комментарии о корретности работы

В ходе работы:
был создан новый проект в Unity, в сцену был добавлен пустой GameObject PerceptronObject, к этому объекту был добавленн пустой C# скрипт, в скрипт внесён код перцептрона, предоставленный преподавателями курса:
```py
using System.Collections;
using System.Collections.Generic;
using UnityEngine;

[System.Serializable]
public class TrainingSet
{
	public double[] input;
	public double output;
}

public class Perceptron : MonoBehaviour {

	public TrainingSet[] ts;
	double[] weights = {0,0};
	double bias = 0;
	double totalError = 0;

	double DotProductBias(double[] v1, double[] v2) 
	{
		if (v1 == null || v2 == null)
			return -1;
	 
		if (v1.Length != v2.Length)
			return -1;
	 
		double d = 0;
		for (int x = 0; x < v1.Length; x++)
		{
			d += v1[x] * v2[x];
		}

		d += bias;
	 
		return d;
	}

	double CalcOutput(int i)
	{
		double dp = DotProductBias(weights,ts[i].input);
		if(dp > 0) return(1);
		return (0);
	}

	void InitialiseWeights()
	{
		for(int i = 0; i < weights.Length; i++)
		{
			weights[i] = Random.Range(-1.0f,1.0f);
		}
		bias = Random.Range(-1.0f,1.0f);
	}

	void UpdateWeights(int j)
	{
		double error = ts[j].output - CalcOutput(j);
		totalError += Mathf.Abs((float)error);
		for(int i = 0; i < weights.Length; i++)
		{			
			weights[i] = weights[i] + error*ts[j].input[i]; 
		}
		bias += error;
	}

	double CalcOutput(double i1, double i2)
	{
		double[] inp = new double[] {i1, i2};
		double dp = DotProductBias(weights,inp);
		if(dp > 0) return(1);
		return (0);
	}

	void Train(int epochs)
	{
		InitialiseWeights();
		
		for(int e = 0; e < epochs; e++)
		{
			totalError = 0;
			for(int t = 0; t < ts.Length; t++)
			{
				UpdateWeights(t);
				Debug.Log("W1: " + (weights[0]) + " W2: " + (weights[1]) + " B: " + bias);
			}
			Debug.Log("TOTAL ERROR: " + totalError);
		}
	}

	void Start () {
		Train(5);
		Debug.Log("Test 0 0: " + CalcOutput(0,0));
		Debug.Log("Test 0 1: " + CalcOutput(0,1));
		Debug.Log("Test 1 0: " + CalcOutput(1,0));
		Debug.Log("Test 1 1: " + CalcOutput(1,1));
	}
	
	void Update () {
		
	}
}
```

Для обучения перцептрона вычислениям OR, были введены следующие данные:![image](https://user-images.githubusercontent.com/113825126/201517814-50f01321-af4a-4820-bfee-866011be0799.png)

Логический элемент OR на онове перцептрона работает коректно, подробнее смотри в Задании 2.

Для обучения перцептрона вычислениям AND, были введены следующие данные:![image](https://user-images.githubusercontent.com/113825126/201517957-cbb29414-317c-451d-b43a-d6029ce0ce04.png)

Логический элемент AND на онове перцептрона работает коректно, подробнее смотри в Задании 2.

Для обучения перцептрона вычислениям NAND, были введены следующие данные:![image](https://user-images.githubusercontent.com/113825126/201517993-08dfdd67-89ea-46e6-8986-5ebca7e7408f.png)

Логический элемент NAND на онове перцептрона работает коректно, подробнее смотри в Задании 2.

Для обучения перцептрона вычислениям XOR, были введены следующие данные:![image](https://user-images.githubusercontent.com/113825126/201518036-3f7bf7d9-cecb-4d04-84b6-b623c1f7fab8.png)

Логический элемент XOR на онове перцептрона, как и ожидалось, работает некоректно, подробнее смотри в Задании 2.


## Задание 2
### Построить граффики зависимости количества ошибок количества эпох обучения. Указать от чего зависит необходимое количество эпох обучения.

Было проведено по 5 эксперементов для каждого количества эпох обучения (от 1 до 5 для OR, от 1 до 7 для остальных).
В конце каждого эксперемента фиксировалось последнее значение TOTAL ERROR, выводимое в консоле.
Значения полученные в результате серии пяти опытов суммировалиь, высчитывалось их среднее арифметическое, это значение заносилось в таблицу Exel.
На основании таблицы создавался соответствующй граффик (по горизонтали - количество эпох обучения): 

Процесс обучения перцептрона вычислениям OR:

![image](https://user-images.githubusercontent.com/113825126/201518992-fc8fcd14-9aaf-435d-bc10-34d1b0a5e7c6.png)

Из графика видно, что с увеличением количества эпох обучения количество ошибок уменьшается.

3 и меньше эпох явно недостаточно, чтобы обучить перцептрон вычислениям OR, 4 эпохи - остаётся неболшая погрешность, 5 эпох - достаточно.

Процесс обучения перцептрона вычислениям AND:

![image](https://user-images.githubusercontent.com/113825126/201519864-b0209330-7e49-41d2-92dc-ba03932d5d6b.png)

Из графика видно, что с увеличением количества эпох обучения количество ошибок сначала быстро увеличивается, а потом постепенно уменьшается.

5 эпох - явно недостаточно, чтобы обучить перцептрон вычислениям AND, 6 эпох - остаётся неболшая погрешность, 7 эпох - достаточно.

Процесс обучения перцептрона вычислениям NAND:

![image](https://user-images.githubusercontent.com/113825126/201520009-f1950c41-fe74-4017-9d26-30e8defe84f6.png)

Ситуация близка к той, что была при обучении вычислениям AND.

Процесс обучения перцептрона вычислениям XOR:

![image](https://user-images.githubusercontent.com/113825126/201520076-b54059ab-8b95-4847-891b-3b898fdcb0e5.png)

В сопутствующей данной лабораторной работе лекции было сказано, что перцептрон неспособен обучиться быть элементом XOR, решать нелинейные задачи, результаты серии проделанных эксперементов это подтверждают. При этом, из графика видно, что с увеличением количества эпох обучения количество ошибок возрастает и достигает значения 4, то есть все 4 коофициента весов перцептрона не подходят для вычислений XOR.

Я предпологаю, что для обучения перцептрона вычислениям AND (NAND) необходимо болше эпох обучения, чем для обучения вычислениям OR, потому что вычисления AND более сложные, чем вычисления OR. Вычисления AND можно представить, как X*Y, где X и Y имеют значения 0 или 1, вычисления OR же можно представить, как X+Y. Подобрать коофициенты для умножения сложнее, чем для сложения.


## Задание 3
### Построить визуальную модель работы перцептрона на сцене Unity


## Выводы
### Абзац умных слов о том, что было сделано и что было узнано.

В ходе данной лабораторной работы я узнал, что такое перцептрон, как он работает, почему разделяют машинное и глубокое обучение, что такое XOR и NAND,
обучил перцептрон выполнять вычисления OR, AND, NAND, проанализировал его работу и оценил его возможности.

## Powered by

**BigDigital Team: Denisov | Fadeev | Panov**
